{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container Orchestration\n",
    "\n",
    "## What is Kubernetes\n",
    "- Kubernetes, also referred to as K8s, is Greek and means helmsman or pilot\n",
    "- - So it's the captain of the ship with all the dcontainers\n",
    "- Kubernetes is an extensive open-source platform for managing containerized workloads and services\n",
    "- It comes from Google Borgn a system that Google has been useing since 2002 to run its applications\n",
    "\n",
    "## What Else is Kubernetes?\n",
    "- It's open-source software for automating deployment, scaling, and orchestration of containerized applications\n",
    "- - Instead of running containers with the **docker** command, you'll use the **kubernetes** command to run them\n",
    "- It is about running multiple connected containers, organized in Pods, or deployments runnimg on different hosts, where community of service is guaranteed\n",
    "- It has become the de factor standard for orchestration of containers\n",
    "- With a new release every 3 months, it is rapidly evolving\n",
    "\n",
    "<img src='screenshots/Simple-Kubernetes-Architecture.png'>\n",
    "\n",
    "## Kubernetes Architecture\n",
    "<img src='screenshots/Kubernetes-Architecture.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Native Computing Foundation\n",
    "- Google donated Kubernetes to the Cloud Native Computing Foundation (CNCF), which is a foundation in Linux Foundation\n",
    "- CNCF is a governing body that solves issues faced by any cloud native allications (so not just Kubernetes)\n",
    "- CNCF owns the copyright to Kubernetes\n",
    "- Kubernetes itself uses an Apache license\n",
    "- Developers need to sign a Contributor License Agreement with CNCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containers\n",
    "\n",
    "## What is a Container?\n",
    "- A container is a solution that bundles an application and all of its dependencies in a box\n",
    "- - Kernel is not included\n",
    "- This box can run on virtually any platform, as long as that platform runs a container engine\n",
    "- Containers are based on an image, from the idmage you can spin multiple containers\n",
    "- - When the container is crete it runs a process on the host kernel. The host kernel isolates resources belonging to each container\n",
    "- - For resource isolation, namespaces are used\n",
    "- - To dedicate resources, cgroups are used\n",
    "\n",
    "## Container Filesystems\n",
    "- Container images consist of different layers\n",
    "- These layers are joined in the union filesystem\n",
    "- By overlaying these layers, a new virtual filesystem is created\n",
    "- The layers are joined in images, and by default are read-only\n",
    "- When a container is started, the ephemeral read-write layer is added\n",
    "\n",
    "## Why Containers are Successful\n",
    "- Very fast deployment\n",
    "- Flexible, as they run anywhere\n",
    "- Easy to scale up and down\n",
    "- Very resource-efficient\n",
    "- Little footprint\n",
    "- Portable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Docker\n",
    "## On Ubuntu\n",
    "### 1. Prerequisites\n",
    "The very first step is to remove any default Docker packages from the system before installation Docker on a Linux VPS. Execute commands to remove unnecessary Docker versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt-get purge docker lxc-docker docker-engine docker.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now install some required packages on your system for installing Docker on Ubuntu system. Run the below commands to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt-get install  curl  apt-transport-https ca-certificates software-properties-common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup Docker Repository\n",
    "Now import dockers official GPG key to verify packages signature before installing them with apt-get. Run the below command on terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that add the Docker repository on your Ubuntu system which contains Docker packages including its dependencies. You must have to enable this repository to install Docker on Ubuntu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Install Docker on Ubuntu\n",
    "Your system is now ready for Docker installation. Run the following commands to upgrade apt index and then install Docker community edition on Ubuntu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-ce\n",
    "sudo systemctl status docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Red Hat\n",
    "### 1. Install yum-utils and epel-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "yum install -y yum-utils\n",
    "wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Docker CE to yum repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Install container-selinux package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "yum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.33-1.git86f33cd.el7.noarch.rpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Install Docker CE\n",
    "The container-selinux package is available from the rhel-7-server-extras-rpms channel. you can enable it using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "subscription-manager repos --enable=rhel-7-server-extras-rpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "yum install -y docker-ce\n",
    "docker --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Restart docker service and enable it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "systemctl restart docker\n",
    "systemctl enable docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mac OS\n",
    "Download docker desktop from docker hub\n",
    "\n",
    "https://hub.docker.com/editions/community/docker-ce-desktop-mac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container Architecture\n",
    "Docker enginge\n",
    "- Docker engine runs containers and consists of the following parts\n",
    "- - A server implemented by the **dockerd** service\n",
    "- - A REST API which specifies interfaces that can be used by client commands\n",
    "- - The **docker** command\n",
    "\n",
    "<img src='screenshots/Container-Architecture.png'>\n",
    "\n",
    "### Docker Registry\n",
    "- Docker registries are used to store Docker images\n",
    "- Docker hub is publicly available and used as the defualt\n",
    "- Docker cloud is also publicly available\n",
    "- Administrators can create private registries\n",
    "- When using **docker pull** or **docker run** as image is pulled from the registry\n",
    "- You can upload images using **docker push**\n",
    "\n",
    "## Docker Objects\n",
    "- **image**: a read-only template with instructions to crate docker container\n",
    "- - Images are often based on their images\n",
    "- - Default images are pulled from Docker registry, you can build yoru own images using Docekrile\n",
    "- - - Each instruction in Dockerfile creates a layer in the image\n",
    "- - - When rebuilding an image, only those layers that are changed are rebuilt\n",
    "- **container**: a runnable instance of an image\n",
    "- - Containers need persistent storage to keep modifications\n",
    "- **services**: used in Docker swarm to scale containers accross multiple Docker daemons\n",
    "\n",
    "## Operational Container Mangement\n",
    "Working with Containers\n",
    "- Show Docker version information: **docker version**\n",
    "- Show current usage information: **docker info**\n",
    "- Search containers: **docker search wordpress**\n",
    "- Download an image: **docker pull wordpress**\n",
    "- Verify: **docker images**\n",
    "- Remove images: **docker rmi wordpress**\n",
    "- Run a container in interactive mode: **docker run -dit --name centos --hostname=\"centos\" centos /bin/bash**\n",
    "- Verify running container: **docker ps -a**\n",
    "- Connect to a container: **docker attach centos**\n",
    "- Run a command in a container: **docker run centos /usr/bin/free -m**\n",
    "- - After running the command, the container stops, but is still available on the system\n",
    "- Run a command in a container and remove the container after doing so: **docker run --rm centos /usr/bin/df/ -h**\n",
    "- - After running the command, the container stops, but is still available on the system\n",
    "- Run a command in a container and remove the container after doing so: **docker run --rm centos /usr/bin/df -h**\n",
    "- Show information about a running contianer: **docker top centos**\n",
    "- Show top-like information about a container: **docker stats centos**\n",
    "- Copy something from the container to localhost: **docker cp centos:/etc/hosts /root/**\n",
    "- Run a command inside a container: **docker exec centos cat /etc/hostname**\n",
    "- Kill a container: **docker kill centos**\n",
    "\n",
    "\n",
    "## When Does Container Stop?\n",
    "- Typically, when a container is started, a specific command is executed. When this command stops, the container stops as well\n",
    "- **docker run --name demo1 centos:latest dd if=/dev/zero of=/dev/null**\n",
    "- - This will start the container, and use the terminal to run the **dd** command\n",
    "- - Use **docker ps** to see the active container\n",
    "- - Use **ps aux**, you'll notice the dd process shows in the current process tree\n",
    "- - Use **docker exec -it demo1 /bin/bash** and type ps aux. You'll see the dd process runnning as PID 1\n",
    "- Type **docker stop domo-container**\n",
    "- Now type **docker run --name demo2 centos:latest sleep 30**\n",
    "- From another terminal, type **docker ps**\n",
    "- Obsrever that the container will stop after executing its task\n",
    "- Type **docker ps -a**, this will show a list of all containers that have been activated in the past\n",
    "- Type **docker rm \\< containername \\>** to remove these containers\n",
    "- - User **docker rm \\$(docker ps -aq)** to delete all containers\n",
    "\n",
    "## Run command on stopped container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# docker commit <container id>\n",
    "# docker run -it <newcontainer id> bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get IP of running container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# docker ps\n",
    "# docker inspect -f '{{ .NetworkSettings.IPAddress }}' <container name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Architecture\n",
    "<img src='screenshots/Docker-Architecture.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Networking\n",
    "<img src='screenshots/Docker-Networking.png'>\n",
    "\n",
    "Docker Networking\n",
    "- Default netowrking uses Linux bridges\n",
    "- - Different containers on othe same host can communicate; communications with containers on theor hosts is not possible\n",
    "- - As the bridge runs NAT, containers are not directly accessible from the outside\n",
    "- Overlay networking: using overlay networking technologies allows containers to communicate if they're running on different hosts\n",
    "- Other technologies do exist, but are irrelevant if you're going to use Kubernetes\n",
    "\n",
    "## Exposing Container Ports\n",
    "- By default, container ports are not accessible from the outside\n",
    "- Use port mapping to make them accessible\n",
    "- - **docker run -d --name httpd -p 8080:80 httpd**\n",
    "- - **curl http://localhost:8080**\n",
    "- Alternatively, you can specify an IP address for the port forward\n",
    "- - **docker run -d --name httpd2 192.168.1.150:8090:80 httpd**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Storage\n",
    "## Default Storage\n",
    "- Containers are based on different filesystem layers\n",
    "- You can modify contents of a running container, but storage by default is ephemeral: it's gone after a restart\n",
    "- All modifications in running containers are written to a read/write filesystem layer that by default is removed when the container is stopped\n",
    "- Notice taht this R/W filesystem layer should not be used for persistent storage, as it doesn't perform well\n",
    "- Also notice that Docker keeps the ephemeral storage around for some time after the container is stopped, making it easier to troubleshoot based on information in logs\n",
    "\n",
    "## Host Directory Storage\n",
    "- Persistent storage can be offered by using a host directory\n",
    "- The container will bind-mount to this host directory to write and access persistent data\n",
    "- - Notice aht RHEL, this host directory should have the svirt_sandbox_file_t context label\n",
    "- On the host directory, use **chown** to set the appropriate UID and GID as owner\n",
    "- - Note that this refers to the UID and GID of a user in the container, which may not exist on othe host. For instance, on a mariadb container, the users that mariadb is using are UID 27 and GID 27. Apply these using **chown -R 27:27 /var/local/mysql**\n",
    "\n",
    "code to configure persistent storage using mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /var/local/mysql\n",
    "apt install selinux-utils\n",
    "setenforce 0\n",
    "chown -R 27:27 /var/local/mysql\n",
    "docker pull mariadb\n",
    "docker run --name mariadb -d -v /var/local/mysql:/var/lib/mysql -e MYSQL_USER=user -e MYSQL_PASSWORD=password -e MYSQL_DATABASE=addresses -e MYSQL_ROOT_PASSWORD=password mariadb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Operating Docker Containers\n",
    "1. Start a container that runs the latest version of nginx\n",
    "2. Verify that the container is available\n",
    "3. Open a shell on the container and look which process currently are running\n",
    "4. Expose your containers webserver port on the Docker host port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker pull nginx\n",
    "docker run -dit --name mynginx -p 8088:80 nginx bash\n",
    "docker ps\n",
    "docker attach mynginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kubectl\n",
    "- **kubectl** is the generic Kubernetes management command\n",
    "- It uses the ~/.kube/config file to find information on what to connect to\n",
    "- It is available for all platforms to allow you to manage Kubernetes\n",
    "- **kubectl** is the management command that needs to be available on the managemnet workstation\n",
    "- You'll use it to interface the Kubernetes cluster, no matter where it will be running\n",
    "- There are differetn ways to install it\n",
    "- - From a cloud client\n",
    "- - Run from a cloud shell\n",
    "- - Compile form source\n",
    "- - Run from the release binaries\n",
    "- We'll install it from the release binaries on linux, and show how to use it on MacOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing kubectl on Linux from Release Binaries\n",
    "\n",
    "1. Download the latest release with the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make the kubectl binary executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "chmod -x kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Move kubectl to /usr/local/bin so that it can be executable from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mv kubectl /usr/local/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check kubectl version, you might see a warning regarding server port forwarding, or localhost:port is not set. This is because we haven't set up minikube yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up port forwarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public (active)\n",
      "  target: default\n",
      "  icmp-block-inversion: no\n",
      "  interfaces: wlp2s0\n",
      "  sources: \n",
      "  services: ssh dhcpv6-client\n",
      "  ports: \n",
      "  protocols: \n",
      "  masquerade: yes\n",
      "  forward-ports: port=8433:proto=tcp:toport=8433:toaddr=192.168.99.100\n",
      "  source-ports: \n",
      "  icmp-blocks: \n",
      "  rich rules: \n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "firewall-cmd --list-all\n",
    "# to get the firewall, mine is public, so I set my zone to be public\n",
    "firewall-cmd --permanent --zone=public --add-masquerade\n",
    "firewall-cmd --permenant --zone=public --add-forward-port=port=8433:proto=tcp:toport=8433:toaddress=192.168.99.100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing kubectl on MacOS from Release Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install homebrew\n",
    "/usr/bin/rube -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n",
    "brew install kubectl\n",
    "kubectl version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minikube\n",
    "- Minikube is a single-VM demo environment that runs on top of VirtualBox\n",
    "- The **minikube start** command will run a VirtualBox VM with a single-node Kubernetes deployment as well as a Docker engine\n",
    "- It's not for production, but it's excellent for learning Kubernetes!\n",
    "\n",
    "## Minikube Requirements\n",
    "- Physical machine\n",
    "- 2 GB of RAM (4GB recommended)\n",
    "- Hardware assested virtualization\n",
    "- No other virtualization stack\n",
    "\n",
    "the ~/.kube file will give you the information about certificate in which you can configure your other machines to connect to your minikube environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# to check if virtualization is supported\n",
    "grep -E --color 'vmx|svm' /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install virtualbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n",
    "  && chmod +x minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo install minikube /usr/local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "minikube start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason for failure if that happens is when minikube don't like your network. Try your home network.\n",
    "\n",
    "Sometimes it can remedied with minikube stop, minikube delete and minikube start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mKubernetes master\u001b[0m is running at \u001b[0;33mhttps://192.168.99.103:8443\u001b[0m\n",
      "\u001b[0;32mKubeDNS\u001b[0m is running at \u001b[0;33mhttps://192.168.99.103:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\u001b[0m\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl cluster-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       STATUS   ROLES    AGE   VERSION\n",
      "minikube   Ready    master   24h   v1.15.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Kubectl\n",
    "## Connecting to a Cluster\n",
    "- Kubernetes uses a **config** file in ~/.kube to specify details about the cluster you want to connect to\n",
    "- When setting up a cluster, this config file is automatically created, you may modify it manually\n",
    "- Use **kubectl config view** to show current configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "clusters:\n",
      "- cluster:\n",
      "    certificate-authority: /home/yi/.minikube/ca.crt\n",
      "    server: https://192.168.99.103:8443\n",
      "  name: minikube\n",
      "contexts:\n",
      "- context:\n",
      "    cluster: minikube\n",
      "    user: minikube\n",
      "  name: minikube\n",
      "current-context: minikube\n",
      "kind: Config\n",
      "preferences: {}\n",
      "users:\n",
      "- name: minikube\n",
      "  user:\n",
      "    client-certificate: /home/yi/.minikube/client.crt\n",
      "    client-key: /home/yi/.minikube/client.key\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ~/.kube\n",
    "cat config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ~/.kube/config file gives us the server, the certificate authority. The client certificate and client key.\n",
    "\n",
    "You will copy over the client certificate and client key in which you copy to other machines that you want to connect to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mKubernetes master\u001b[0m is running at \u001b[0;33mhttps://192.168.99.103:8443\u001b[0m\n",
      "\u001b[0;32mKubeDNS\u001b[0m is running at \u001b[0;33mhttps://192.168.99.103:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\u001b[0m\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n",
      "NAME       STATUS   ROLES    AGE   VERSION\n",
      "minikube   Ready    master   24h   v1.15.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl cluster-info\n",
    "kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ssh into minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "minikube ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show ip of minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "minikube ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minikube dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "minikube dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minikube log information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "minikube logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kubectl run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create and run a particular image, possibly replicated.\n",
      "\n",
      " Creates a deployment or job to manage the created container(s).\n",
      "\n",
      "Examples:\n",
      "  # Start a single instance of nginx.\n",
      "  kubectl run nginx --image=nginx\n",
      "  \n",
      "  # Start a single instance of hazelcast and let the container expose port 5701 .\n",
      "  kubectl run hazelcast --image=hazelcast --port=5701\n",
      "  \n",
      "  # Start a single instance of hazelcast and set environment variables \"DNS_DOMAIN=cluster\" and \"POD_NAMESPACE=default\" in the container.\n",
      "  kubectl run hazelcast --image=hazelcast --env=\"DNS_DOMAIN=cluster\" --env=\"POD_NAMESPACE=default\"\n",
      "  \n",
      "  # Start a single instance of hazelcast and set labels \"app=hazelcast\" and \"env=prod\" in the container.\n",
      "  kubectl run hazelcast --image=hazelcast --labels=\"app=hazelcast,env=prod\"\n",
      "  \n",
      "  # Start a replicated instance of nginx.\n",
      "  kubectl run nginx --image=nginx --replicas=5\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl run --help | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl run nginx -- image=nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kubectl get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl get --help | head -15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       READY   STATUS    RESTARTS   AGE\n",
      "mynginx-8567cfb87c-892xw   1/1     Running   0          19h\n",
      "mynginx-8567cfb87c-8mxhw   1/1     Running   0          19h\n",
      "nginx-7bb7cd8db5-glkr6     1/1     Running   0          20h\n",
      "NAME         ENDPOINTS             AGE\n",
      "kubernetes   192.168.99.103:8443   25h\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get pods\n",
    "kubectl get endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Kubernetes config file\n",
    "- Config file is used to define 3 different elements:\n",
    "- - cluster: the kubernetes cluster\n",
    "- - user: the authorized user\n",
    "- - context the part of the cluster the user wants to access, typically a namespace\n",
    "- Multiple clusters, users and contexts can be referred to from one config file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "clusters:\n",
      "- cluster:\n",
      "    certificate-authority: /home/yi/.minikube/ca.crt\n",
      "    server: https://192.168.99.103:8443\n",
      "  name: minikube\n",
      "contexts:\n",
      "- context:\n",
      "    cluster: minikube\n",
      "    user: minikube\n",
      "  name: minikube\n",
      "current-context: minikube\n",
      "kind: Config\n",
      "preferences: {}\n",
      "users:\n",
      "- name: minikube\n",
      "  user:\n",
      "    client-certificate: /home/yi/.minikube/client.crt\n",
      "    client-key: /home/yi/.minikube/client.key\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ~/.kube/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a Remote Cluster\n",
    "- When setting up a cluster, the config file is created automatically\n",
    "- To connect to a remote cluster, you'll need to set up appropriate credentials, consisting of a client certificate and a client key\n",
    "- User **kubectl config set-cluster mycluster --server=http://ip:port --api-version=-v1** to connect to the cluster\n",
    "- Next, use **kubectl use-context mycluster** to start fusing it\n",
    "- When working with multiple configuration files, set the KUBECONFIG variable with as the argument a list of config files where each file is separated by a \":\"\n",
    "\n",
    "link to kubernetes document to config multiple clusters\n",
    "https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Images into Kubernetes\n",
    "## Workflow Overview\n",
    "- Use Docker images to create pods\n",
    "- Kubernetes uses Pods as the smallest managed items\n",
    "- - Kubernetes doesn't manage containers, it manages pods\n",
    "- Easily create basic Pods using the dashboard\n",
    "- Or use YAML files for increased scalability\n",
    "- To start using Kubernetes, you'll need to pull container images into the pods\n",
    "- To use custom images, create your own Docker images and push them to the registry\n",
    "- Alternatively, pull images from public containers\n",
    "- - Use Docker Hub or any private container registry\n",
    "- - Using Docker Hub images makes sense in a small private deployment\n",
    "- Use the Kubernetes Dashboard for an easy way to get started\n",
    "- - Start through **minkube dahboard**\n",
    "- - Or by addressing port 30000 on the Kubernetes Master node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pods with YAML Files\n",
    "- use **kubectl** with a YAML file to make creating pods easy\n",
    "- **kubectl create -f /< name />.yaml --validate=false**\n",
    "- **kubectl get pods** will show the new pod\n",
    "- **kubectl describe pods** shows all details about pods, including the information about its containers\n",
    "- - **kubectl describe pods busybox**\n",
    "- - **kubectl describe pods busybox -o yaml**\n",
    "- - **kubectl describe pods busybox -o json**\n",
    "\n",
    "The following is the script for busybox.yaml"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// busybox.yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: busybox\n",
    "  namespace: default\n",
    "spec:\n",
    "  containers:\n",
    "  - name: busybox\n",
    "    image: busybox\n",
    "    command:\n",
    "      - sleep\n",
    "      - \"3600\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create pods using busybox.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/busybox created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd yaml-files\n",
    "kubectl create -f busybox.yaml --validate=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       READY   STATUS    RESTARTS   AGE\n",
      "busybox                    1/1     Running   0          63s\n",
      "mynginx-8567cfb87c-892xw   1/1     Running   2          3d8h\n",
      "mynginx-8567cfb87c-8mxhw   1/1     Running   2          3d8h\n",
      "nginx-7bb7cd8db5-glkr6     1/1     Running   2          3d9h\n",
      "Name:         busybox\n",
      "Namespace:    default\n",
      "Priority:     0\n",
      "Node:         minikube/10.0.2.15\n",
      "Start Time:   Wed, 18 Sep 2019 20:46:13 -0700\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "Status:       Running\n",
      "IP:           172.17.0.8\n",
      "Containers:\n",
      "  busybox:\n",
      "    Container ID:  docker://22d8b9de343d961e8c9f2bbc17597392bd25fd07472b9f2e1b2471fc21e9d1b5\n",
      "    Image:         busybox\n",
      "    Image ID:      docker-pullable://busybox@sha256:fe301db49df08c384001ed752dff6d52b4305a73a7f608f21528048e8a08b51e\n",
      "    Port:          <none>\n",
      "    Host Port:     <none>\n",
      "    Command:\n",
      "      sleep\n",
      "      3600\n",
      "    State:          Running\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get pods\n",
    "kubectl describe pods busybox | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Running a Kubernetes Application\n",
    "Instructions\n",
    "- Lookup the images that are available to deploy an Apache web server as kubernetes application\n",
    "- Write a YAML file that runs the Apache web server\n",
    "- Verify its operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker search apache"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// apache.yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: apache\n",
    "  namespace: default\n",
    "spec:\n",
    "  containers:\n",
    "  - name: apache\n",
    "    image: httpd\n",
    "    command:\n",
    "      - sleep\n",
    "      - \"3600\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/apache created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd yaml-files\n",
    "kubectl create -f apache.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       READY   STATUS              RESTARTS   AGE\n",
      "apache                     0/1     ContainerCreating   0          13s\n",
      "busybox                    1/1     Running             0          17m\n",
      "mynginx-8567cfb87c-892xw   1/1     Running             2          3d8h\n",
      "mynginx-8567cfb87c-8mxhw   1/1     Running             2          3d8h\n",
      "nginx-7bb7cd8db5-glkr6     1/1     Running             2          3d10h\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Components\n",
    "## Kubernetes Resource\n",
    "<img src='screenshots/Kubernetes-Resource.png'>\n",
    "\n",
    "\n",
    "namespace: restrict isolation between resources\n",
    "\n",
    "<img src='screenshots/Namespace.png'>\n",
    "\n",
    "## Pod\n",
    "- A group of one or more containers, share storage and networking, and a specification of how to run these containers\n",
    "- All containers in the pod are always co-located and co-scheduled\n",
    "- Everything within a pod runs within a shared context\n",
    "- You can see a pod as an application or logical host\n",
    "- Pods are considered to be ephemeral, if a pod is stopped it to go away\n",
    "- If the node running a pod crashes, the pod will be schedule to go somewhere else\n",
    "- Pods implement the application you want to offer to end users\n",
    "- Everything within a pod needs to work together, so you don't want to work at a container level\n",
    "- Containers in the pod have the following requirements which make sense running them in he same pod\n",
    "- - deployment: it all belong together\n",
    "- - co-location\n",
    "- - shared fate, as containers depends on one another\n",
    "- - resource sharing\n",
    "- - dependency management\n",
    "\n",
    "## Pod Networking\n",
    "- Applications in a pod all use the same network namespace\n",
    "- - One IP address for the pod\n",
    "- - One range of ports that needs to be shared by all containers in the pod\n",
    "- Therefore, containers in a pod must coordinate their usage of ports\n",
    "- Each pod has one IP address\n",
    "- The hostname to that IP address is set to the pods name\n",
    "\n",
    "## Starting Pods\n",
    "- Individual Pods can be started using **kubectl create -f /< name />.yaml**\n",
    "- Alternatively, use the Dashboard running on port 30000\n",
    "- After starting a pod, use **kubectl get pods** to get an overview of all running pods\n",
    "- **kubectl describe pods** showsd all details about a pod\n",
    "- Use **kubectl delete pod podname** to delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Namespaces\n",
    "- A namespace is a strict isolation that occurs on Linux kernel level\n",
    "- - It is like building datacenters in a kubernetes environment\n",
    "- - One namespace is not visible from another namespace\n",
    "- Every **kubectl** request uses namespaces to ensure that resources are strictly separated and names don't have to be unique\n",
    "- Namespaces can be added when creating a pod, thus ensuring that a pod is available in a specific namespace only\n",
    "- Before adding a pod to a namespace, ensure that the namespace exists\n",
    "- Use namespaces in cluster environments with many users that are spread across multiple teams and projects\n",
    "\n",
    "## Default Namespaces\n",
    "- By default, Kubernetes has 3 namespaces\n",
    "- - default\n",
    "- - kube-public\n",
    "- - kube-system\n",
    "\n",
    "## Working with namespace\n",
    "- **kubectl get ns** will list all the namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME              STATUS   AGE\n",
      "default           Active   3d23h\n",
      "kube-node-lease   Active   3d23h\n",
      "kube-public       Active   3d23h\n",
      "kube-system       Active   3d23h\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specifying namespace of a pod in a yaml file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// busybox-ns.yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: busybox2\n",
    "  namespace: secret\n",
    "spec:\n",
    "  containers:\n",
    "  - image: busybox\n",
    "    name: busy\n",
    "    command:\n",
    "      - sleep\n",
    "      - \"3600\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must first create the namespace before creating a pod that belongs to that namespace.\n",
    "\n",
    "To create a namespace us\n",
    "- **kubectl create ns /< name of namespace />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/secret created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create ns secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod/busybox2 created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd yaml-files\n",
    "kubectl create -f busybox-ns.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: Namespace\n",
      "metadata:\n",
      "  creationTimestamp: \"2019-09-19T13:29:16Z\"\n",
      "  name: secret\n",
      "  resourceVersion: \"165156\"\n",
      "  selfLink: /api/v1/namespaces/secret\n",
      "  uid: 7d49d16a-33d0-4d1f-b818-a866f79f69d9\n",
      "spec:\n",
      "  finalizers:\n",
      "  - kubernetes\n",
      "status:\n",
      "  phase: Active\n",
      "{\n",
      "    \"apiVersion\": \"v1\",\n",
      "    \"kind\": \"Namespace\",\n",
      "    \"metadata\": {\n",
      "        \"creationTimestamp\": \"2019-09-19T13:29:16Z\",\n",
      "        \"name\": \"secret\",\n",
      "        \"resourceVersion\": \"165156\",\n",
      "        \"selfLink\": \"/api/v1/namespaces/secret\",\n",
      "        \"uid\": \"7d49d16a-33d0-4d1f-b818-a866f79f69d9\"\n",
      "    },\n",
      "    \"spec\": {\n",
      "        \"finalizers\": [\n",
      "            \"kubernetes\"\n",
      "        ]\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"phase\": \"Active\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get ns secret -o yaml\n",
    "kubectl get ns secret -o json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replica Sets\n",
    "- The pod is the most basic entity in Kubernetes\n",
    "- Replica sets come next and are used to determine the number of instances that are needed of a pod\n",
    "- Replica sets replace replication controllers  that were used in previous versions of Kubernetes\n",
    "- - Replication controller-based commands like **kubectl get rc** won't work anymore\n",
    "- Replication sets can be created directly, buit shouldn't use deployments instead\n",
    "- Applications that are launched through a deployment automatically create replica sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/nginx-1 created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl run nginx-1 --image=nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "mynginx   2/2     2            2           3d19h\n",
      "nginx     1/1     1            1           74s\n",
      "nginx-1   1/1     1            1           35s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 DESIRED   CURRENT   READY   AGE\n",
      "mynginx-8567cfb87c   2         2         2       3d19h\n",
      "nginx-1-75ff6fd8c7   1         1         1       45s\n",
      "nginx-7bb7cd8db5     1         1         1       84s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling up replica set using scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set a new size for a Deployment, ReplicaSet, Replication Controller, or StatefulSet.\n",
      "\n",
      " Scale also allows users to specify one or more preconditions for the scale action.\n",
      "\n",
      " If --current-replicas or --resource-version is specified, it is validated before the scale is attempted, and it is guaranteed that the precondition holds true when the scale is sent to the server.\n",
      "\n",
      "Examples:\n",
      "  # Scale a replicaset named 'foo' to 3.\n",
      "  kubectl scale --replicas=3 rs/foo\n",
      "  \n",
      "  # Scale a resource identified by type and name specified in \"foo.yaml\" to 3.\n",
      "  kubectl scale --replicas=3 -f foo.yaml\n",
      "  \n",
      "  # If the deployment named mysql's current size is 2, scale mysql to 3.\n",
      "  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql\n",
      "  \n",
      "  # Scale multiple replication controllers.\n",
      "  kubectl scale --replicas=5 rc/foo rc/bar rc/baz\n",
      "  \n",
      "  # Scale statefulset named 'web' to 3.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl scale --help | head -20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicaset.extensions/nginx-1-75ff6fd8c7 scaled\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl scale rs nginx-1-75ff6fd8c7 --replicas=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 DESIRED   CURRENT   READY   AGE\n",
      "mynginx-8567cfb87c   2         2         2       3d19h\n",
      "nginx-1-75ff6fd8c7   1         1         1       4m44s\n",
      "nginx-7bb7cd8db5     1         1         1       5m23s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doens't work because scaling occurs at deployment level not replica level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions/nginx-1 scaled\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl scale --replicas=3 deployment nginx-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 DESIRED   CURRENT   READY   AGE\n",
      "mynginx-8567cfb87c   2         2         2       3d19h\n",
      "nginx-1-75ff6fd8c7   3         3         3       6m42s\n",
      "nginx-7bb7cd8db5     1         1         1       7m21s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
