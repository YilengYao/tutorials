{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memcache\n",
    "https://memcached.org/about\n",
    "\n",
    "Memcachee is an in-memory Key-Value pair data store\n",
    "- Put a value with a key\n",
    "- Get a value with a key\n",
    "\n",
    "Basic building block for a distributed key-value store\n",
    "- Trillions of items\n",
    "- Billiions of requests/second\n",
    "\n",
    "Network attached in-memory hash table\n",
    "- Supports LRU based eviction\n",
    "\n",
    "Memcached\n",
    "- Memcached is a caching system. It supports very high performance in a distrubuted system. It helps in reducing the load on a backedn database system.\n",
    "\n",
    "<img src=\"Memcache/Memcached-Architecture.png\" height=\"30%\" width=\"30%\">\n",
    "\n",
    "- Memcached is a `fast access short term memory` solution for an application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memcached Under the Hood\n",
    "\n",
    "Memcached is a memory based caching mechanism and build using C language.\n",
    "\n",
    "Internally, Memcached uses the `least recently used cache` mechanism. After a specific amount of time, the items in memory get expired.\n",
    "\n",
    "<img src=\"Memcache/Memcache-LRU.png\" height=\"30%\" width=\"30%\">\n",
    "\n",
    "### Memcached Performance\n",
    "- Memcached aims for implementation most of the data access operations in O(1) scale.\n",
    "- Queries are targeted to run in less than 1ms\n",
    "- There are high end Memcached servers that can serve millions of keys per second.\n",
    "- Memcached servers are disconnected from each other. Tere is no overhead of data synchronization, broadcasting, cross talk or replication. this helps in providing high performance throughput for read operation.\n",
    "\n",
    "\n",
    "- The implementation logic of Memcached is distributed in client as well as server.\n",
    "- Clients know which server to reach out for which data.\n",
    "- Servers manage the logic of storing and evicting data from the cache.\n",
    "\n",
    "### Key Value Store\n",
    "- In Memcached, data is stored as a key value pair.\n",
    "- The stored data can be of any type.\n",
    "- The only thing that the server expects is that data should be pre-serialized.\n",
    "\n",
    "|key|value|\n",
    "|--|--|\n",
    "|firstName|Bugs|\n",
    "|lastName|Bunny|\n",
    "|location|Earth|\n",
    "\n",
    "#### Expiration\n",
    "Data items in Memcached contain a key, raw data, expiration time and some operational flags.\n",
    "\n",
    "#### Memcache has a fixed amount of Memory\n",
    "If you store data when memory is full, data will get evicted.\n",
    "- Usually data with the oldest timestamp will get evicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases for Memcache\n",
    "Caching\n",
    "- Datastore query results\n",
    "- User authentication token and session data\n",
    "- APIs call or other computation results\n",
    "\n",
    "Share Data Cross App Instances\n",
    "\n",
    "## Why do we need Memcache?\n",
    "- Improve Application Performance\n",
    "- Reduce Application Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Memcache Usage Pattern\n",
    "Coordinate data *read* with Datastore:\n",
    "- Check if Memcache value exists\n",
    "- - if it does, displays/uses cached value directly; otherwise\n",
    "- - fetch t he value form Datastore and write the value to Memcache\n",
    "\n",
    "Coordinate data *write* with Datastore:\n",
    "- Invalidate the Memcache value \n",
    "- - for this specific entry; or\n",
    "- - entire Memcache\n",
    "- Write the value to Datastore\n",
    "- - Optionally, update the Memcache entry\n",
    "\n",
    "### Batch Operations\n",
    "- `getAll()`, `putAll()`, `deleteAll()`\n",
    "- - A single read or write operation for multiple memcache entries\n",
    "\n",
    "### Atomic Operations\n",
    "- `increment(key, delta)`, `incrementAll(...)`,\n",
    "- - Provide atomic increment of numeric value(s)\n",
    "\n",
    "- `getIdentifiable()`, `putIfUntouched()`\n",
    "- - A mechanism to update a value consistently by concurrent requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Features\n",
    "- Asynchronous calls: Provides a mechanism to make a *non-blocking* calll for memcache operations\n",
    "- Namespace: Logically separates data layers for different application purposes (like multi tenancy) acrosss many GAE services such as Datastore, Memcache, Task Queue etc...\n",
    "\n",
    "## Cons with using Memcache\n",
    "\n",
    "### Memcache is Volitile\n",
    "Entries can be evicted anytime by various reasons:\n",
    "- entry reaches expiration\n",
    "- entry is evicted because memecache memory is full\n",
    "- memcache server fails\n",
    "\n",
    "Tip\n",
    "- It's important to handle cache-miss gracefully!\n",
    "- Implements write-though logic by backing memcache with datastore in your application!\n",
    "\n",
    "### Memcache is not Transactional\n",
    "eg. you have 100, you perform 2 subtraction operations.\n",
    "- Subtract 20\n",
    "- Subtract 30 before previous operation is finished\n",
    "\n",
    "The value at the end is 70\n",
    "\n",
    "Tip\n",
    "- User `getIdentifiable()` and `putIfUntouched(...)` for optimistic locking\n",
    "\n",
    "This will cause stale data\n",
    "#### Solution (Leases)\n",
    "Extend memcache protocol with \"leases\"\n",
    "- Return and attach a lease-id with every miss\n",
    "- Lease-id is invalidated inside server on a delete\n",
    "- Disallow set if the lease-id is invalid at the server\n",
    "\n",
    "### Memcache is A Limited Resource\n",
    "My Application Does NOT Have Enough Memcache!\n",
    "\n",
    "Tips\n",
    "- Only need to cache what is useful and necessary!\n",
    "- Your application should function without memcache!\n",
    "\n",
    "### Thundering Herds Provlem with Look-Aside caching\n",
    "If a large amount of read request are looking in memcache for a value that does not exist in memcache, the servers will look for the value in database. But database cannot handle large read loads.\n",
    "\n",
    "#### Solution\n",
    "Memcache server arbitrates access to atabase\n",
    "- Small extension of leases\n",
    "\n",
    "Clients given a choice of usinga slightly stal value or waiting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memcached on Java\n",
    "Spy Memcached (Memcached Java Client), to connect Java application to Memcached\n",
    "\n",
    "api docs for spy memcache\n",
    "\n",
    "https://dustin.github.io/java-memcached-client/apidocs/\n",
    "\n",
    "sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        MemcachedClient c=new MemcachedClient(\n",
    "                new InetSocketAddress(\"hostname\", portNum));\n",
    "\n",
    "        // Store a value (async) for one hour\n",
    "        c.set(\"someKey\", 3600, someObject);\n",
    "        // Retrieve a value.\n",
    "        Object myObject=c.get(\"someKey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memcache at Facebook\n",
    "### Infrastructure Requirements for Facebook\n",
    "1. Near real-time communication\n",
    "1. Aggregate content on-the-fly from multiple sources\n",
    "1. Be able to access and update very popular shared content\n",
    "1. Scale to process millions of user requests per second\n",
    "\n",
    "### Design Requirements\n",
    "Support a very heavy read load\n",
    "- Over 1 billion reads / second\n",
    "- Insulate backend services from high read rates\n",
    "\n",
    "Geographically Distributed\n",
    "\n",
    "Support a constantly evolving product\n",
    "- System must be flexible enough to support a variety of use cases\n",
    "- Support rapid deployment of new features\n",
    "\n",
    "Persistence handled outside the system\n",
    "- Support mechanisms to refill after updates\n",
    "\n",
    "### Many memcache servers in one cluster\n",
    "Items are distributed acrosss memcache servers by using consistent hashing on the key\n",
    "- Individual items are reaely accessed very frequently over replication doens't make sense\n",
    "All web servers talk to all memcache servers\n",
    "- Accessing 100s of memcache serviers to process a user' equest is common\n",
    "\n",
    "<img src=\"Memcache/Memcache-Facebook-many-servers-one-cluster.png\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "#### Problem Incast congestion\n",
    "Many simultaneous response overwhelm the client servers making the request\n",
    "\n",
    "<img src=\"Memcache/Memcache-Facebook-many-servers-one-cluster-incastcongestion.png\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "Solution:<br>\n",
    "Limit the number of outstanding requests with a sliding window\n",
    "- Larger windows cause result in more congestion\n",
    "- Smaller windows result in more orund trips to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many memcache servers in multiple clusters\n",
    "All-to-all limits horizontal scaling\n",
    "\n",
    "Multiple memcache clusters front one DB installation\n",
    "- have to keep the caches consistent\n",
    "- Have to manager over-replication of data\n",
    "\n",
    "#### Databases invalidate caches\n",
    "<img src=\"Memcache/Memcache-Facebook-databases-invalidate-caches.png\" height=\"30%\" width=\"30%\">\n",
    "Cached data must be invalidated after database updates\n",
    "\n",
    "Solution: Tail the mysql commit log and issue deletes based on transactions that have been committed\n",
    "- Allows caches to be resynchronized in the event of a problem\n",
    "\n",
    "Invalidation pipeline problem: Too many packets\n",
    "- Aggregating deletes reduces packet rate by 18x\n",
    "- Makes configuration management easier\n",
    "- Each stage buffers deletes in case downstream component is down\n",
    "\n",
    "Putting it all together\n",
    "1. Single-front-end cluster\n",
    "- - Read heavy workload\n",
    "- - Wide fanout\n",
    "- - Handling failures\n",
    "2. Multiple front-end clusters\n",
    "- - Controlling data replication\n",
    "- - Data consistency\n",
    "3. Multiple Regions\n",
    "- - Data consistency\n",
    "\n",
    "Lessons Learned\n",
    "- Push complexity into the client whenever possible\n",
    "- Operational efficiency is as important as performance\n",
    "- Separating cache and persistent store allows them to be scaled independently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.9+11-LTS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
